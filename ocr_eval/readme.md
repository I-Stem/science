### OCR EVALUATION  
ocr_eval_metrics.ipynb -  Combines individual file results and calculates overall metrics for the dataset.  
html - Contains the html output files.   
text_comparison - Text alignments (OCR text vs Ground truth).  
results - Individual file results.  
Average text accuracy = 91.74%  
Average F1 score = .87
Average table text accuracy=  90.84%  
Total files used =  68 
Ground truths can be found at - https://github.com/I-Stem/ocr_dataset
