## OCR EVALUATION  
ocr_eval_metrics.ipynb -  Combines individual file results and calculates overall metrics for the dataset.  
html - Contains the html output files.   
text_comparison - Text alignments (OCR text vs Ground truth).  
results - Individual file results. 
  
### Current Metrics  
This section reflects the current metrics of our AI model and are being continuously updated as we make progress
Average text accuracy = 91.74%  
Average F1 score = 0.87  
Average table text accuracy=  90.84%  
Total files used =  68  
Ground truths can be found at - https://github.com/I-Stem/ocr_dataset
