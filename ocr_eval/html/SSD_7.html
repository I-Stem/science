<html><head><style>
        table, th, td {
          border: 1px solid black;
          border-collapse: collapse;
        }
        </style></head><body><h6>Page 1</h6><span idx = 1><h6>Column 1</h6><p id=1>TABLE III: Benchmarking ScanSSD at the Character Level A). Note differences in data sets and evaluation techniques (see main text).</p><table><tr><td></td><td>Math </td><td>Symbol </td><td></td></tr><tr><td>System </td><td>Precision </td><td>Recall </td><td>F-score </td></tr><tr><td>ScanSSD </td><td>0.889 </td><td>0.965 </td><td>0.925 </td></tr><tr><td>InftyReader' </td><td>0.971 </td><td>0.946 </td><td>0.958 </td></tr><tr><td>ME U-Net </td><td>0.973 </td><td>0.950 </td><td>0.961 </td></tr></table></br></br><p id=2>' Used GTDB dataset Used TFD-ICDAR2019v2 dataset IOU 2 0.5 IOU 2 0.75 0.9 0.8787 0.8586 0.8269 0.8098 8 0.7801 0.7747 0.82260.7669 0.7747 0.7667 0.7 2580.6816 0.7022 f-score 0.6 0.589 0.5 Jones83 Lusztig89 Erbe 94 Gidas 79 Li75 Emden76 Katz99 Lorentz48 Kontsevich94 Kazhdan79 Filename</p><p id=3>Fig. 7: Document-level results, IOU _ 0.5 and IOU _ 0.75.</p><p id=4>Math symbol detection. To measure math detection at the Detector (SSD) using a sliding window, followed by symbol (character) level, we consider all characters located within formula detections as 'math' characters. Our method has 0.9652 recall and 0.889 precision at the character level, resulting in a 0.925 f-score. This benchmarks well against recent results on the GTDB dataset (see Table III]). Note that the detection targets (formulas for ScanSSD vs. characters), datasets, and evaluation protocols are different (1000 regions per test page are randomly sampled in Ohayama et al. [4]), and so the measures are not directly comparable. The lower precision for character detection in ScanSSD may be an artifact of predicting formulas rather than individual</p><p id=5>characters. The difference between ScanSSD's math symbol detection f-score and formula detection f-score is primarily due to merging and splitting formula regions, which themselves are often valid subexpressions. Merging and improved pooling will reduce the number of over-merged splitting valid formula regions often produces regions too large or too small to satisfy the IOU matching criteria, leading to lower scores. Merging occurs in part because formula detections in neighboring text lines may overlap, and splitting may occur because large formulas have features similar to separate formulas within windowed sub-images. C. Qualitative results Figure [5] provides example ScanSSD detection results. ScanSSD can detect math regions of arbitrary size, from a supported by the Alfred P. Sloan Foundation under Grant</p></span><span idx = 2><h6>Column 2</h6><p id=1>single character to hundreds of characters. It also detects matrices and correctly rejects equation numbers, page numbers, and other numbers not belonging to formulas. Figure 6 shows some example of detection errors. When there is a large space between characters within a formula (e.g ., for variable constraints shown in the third panel of Figure [6), ScanSSD may split the formula and generate multiple detections (shown with pink boxes). Second, when formulas are close to each other, our method may merge them (shown with green boxes in Figure 6). Another error not shown, was wide embedded graphs (visually similar to functions) being detected as math formulas.</p><p id=2>On examination, it turns out that most detection 'failures' are because of valid detections merged or split in the manner described, and not spurious detections or false negatives. A small number of these are seen in Figure 6 using red and yellow boxes; note that all but one false negative are isolated symbols.</p><h1>VII. CONCLUSION</h1><p id=3>In this paper we make two contributions: 1) modifying the GTDB datasets to compensate for differences in scale and translation found in the publicly available versions of PDFs in the collection, creating new bounding box annotations for math expressions, and 2) the ScanSSD architecture for detecting math expressions in document images without using page layout, font, or character information. The method is simple but effective, applying a Single-Shot voting-based pooling across windows and scales.</p><p id=4>Through our experiments, we observed that 1) carefully selected default boxes improves formula detection, 2) kernels of size 1 x 5 yield rectangular receptive fields that better-fit wide math expressions with larger aspect ratios, and avoid noise that square-shaped receptive fields introduce. A key difference between formula detection in typeset documents and object detection in natural scenes is that typeset documents avoid occlusion of content by design. This constraint may help us design a better algorithm for</p><p id=5>non-maximal suppression, as the original non-maximal suppression algorithm is designed to handle overlapping objects. Also, we would like to use a modified version of the pooling methods based on agglomerative clustering such as the fusion algorithm introduced by Yu et al. [34]. We believe and split detections, improving both precision and recall.</p><p id=6>In our current architecture, we use a fixed pooling method; we plan to design an architecture where we can train the model end-to-end to learn pooling parameters directly from data. ScanSSD allows the use of multiple classes, and we would also like to explore detecting multiple page objects in a single framework.</p><p id=7>Acknowledgements. This material is based upon work</p></span><body></html>