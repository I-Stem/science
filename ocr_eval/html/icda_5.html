<html><head><style>
        table, th, td {
          border: 1px solid black;
          border-collapse: collapse;
        }
        </style></head><body><h6>Page 1</h6><span idx = 1><h6>Column 1</h6><table><tr><td></td><td></td><td>Per-document averages </td><td></td><td>Tables (total=156) </td><td>found </td></tr><tr><td>Participant </td><td>Recall </td><td>Precision </td><td>F1-meas. </td><td>Complete </td><td>Pure </td></tr><tr><td>FineReader </td><td>0.9971 </td><td>0.9729 </td><td>0.9848 </td><td>142 </td><td>148 </td></tr><tr><td>OmniPage </td><td>0.9644 </td><td>0.9569 </td><td>0.9606 </td><td>141 </td><td>130 </td></tr><tr><td>Silva </td><td>0.9831 </td><td>0.9292 </td><td>0.9554 </td><td>149 </td><td>137 </td></tr><tr><td>Nitro </td><td>0.9323 </td><td>0.9397 </td><td>0.9360 </td><td>124 </td><td>144 </td></tr><tr><td>Nurminen </td><td>0.9077 </td><td>0.9210 </td><td>0.9143 </td><td>114 </td><td>151 </td></tr><tr><td>Acrobat </td><td>0.8738 </td><td>0.9365 </td><td>0.9040 </td><td>110 </td><td>141 </td></tr><tr><td>Yildiz </td><td>0.8530 </td><td>0.6399 </td><td>0.7313 </td><td>100 </td><td>94 </td></tr><tr><td>Stoffel </td><td>0.6991 </td><td>0.7536 </td><td>0.7253 </td><td>79 </td><td>66 </td></tr><tr><td>Liu et al. 2 </td><td>0.3355 </td><td>0.8836 </td><td>0.4864 </td><td>0 </td><td>29 </td></tr><tr><td>Hsu et al. </td><td>0.4601 </td><td>0.3666 </td><td>0.4080 </td><td>39 </td><td>95 </td></tr><tr><td>Fang et al. </td><td>0.2697 </td><td>0.7496 </td><td>0.3967 </td><td>28 </td><td>41 </td></tr><tr><td>Liu et al. 1 </td><td>0.2207 </td><td>0.8885 </td><td>0.3536 </td><td>0 </td><td>25 </td></tr></table></br></br><p id=1>TABLE II RESULTS FOR THE TABLE LOCATION (LOC) SUB-COMPETITION</p><table><tr><td></td><td>Per-document </td><td>averages </td><td></td></tr><tr><td>Participant </td><td>Recall </td><td>Precision </td><td>F1-measure </td></tr><tr><td>Nurminen </td><td>0.9409 </td><td>0.9512 </td><td>0.9460 </td></tr><tr><td>Silva </td><td>0.6401 </td><td>0.6144 </td><td>0.6270 </td></tr><tr><td>Hsu et al. </td><td>0.4811 </td><td>0.5704 </td><td>0.5220 </td></tr></table></br></br><p id=1>Per-document averages</p><p id=2>TABLE III RESULTS FOR THE TABLE STRUCTURE RECOGNITION (STR) SUB-COMPETITION (BASED ON CORRECT REGION INFORMATION )</p><table><tr><td></td><td>Per-document </td><td>averages </td><td></td></tr><tr><td>Participant </td><td>Recall </td><td>Precision </td><td>F1 -measure </td></tr><tr><td>FineReader </td><td>0.8835 </td><td>0.8710 </td><td>0.8772 </td></tr><tr><td>OmniPage </td><td>0.8380 </td><td>0.8460 </td><td>0.8420 </td></tr><tr><td>Nurminen </td><td>0.8078 </td><td>0.8693 </td><td>0.8374 </td></tr><tr><td>Acrobat </td><td>0.7262 </td><td>0.8159 </td><td>0.7685 </td></tr><tr><td>Nitro </td><td>0.6793 </td><td>0.8459 </td><td>0.7535 </td></tr><tr><td>Silva </td><td>0.7052 </td><td>0.6874 </td><td>0.6962 </td></tr><tr><td>Yildiz </td><td>0.5951 </td><td>0.5752 </td><td>0.5850 </td></tr></table></br></br><p id=3>TABLE IV TABLE STRUCTURE RECOGNITION RESULTS FOR THE COMPLETE PROCESS (COM) - BASED ON THE SYSTEM'S TABLE LOCATION RESULT</p><p id=4>Our evaluation metrics were found to be a fair representation of the actual quality of the output from the various systems. The combination of completeness and purity with precision and recall on the character level gives a good overall picture of the region detection quality. Similarly, we have found that using cell adjacency relations to evaluate table structure detection enables us to obtain precision and recall measures which are repeatable and accurately reflect the quality of the result.</p><p id=5>By calculating the results for each document first, we were able to reduce the bias of "data-heavy" tables on the overall result. A further improvement for the future would be to evaluate regions by calculating the area (in square points) of region overlap instead of counting characters, after "normalizing" each region first by shrinking it to the smallest region encompassing all characters within its bounds. This would avoid regions containing overprinted or non-printing characters skewing the result.</p><p id=6>The structure results for the complete process (see Table IV) should also be treated with some caution. A number of systems 1453</p></span><span idx = 2><h6>Column 2</h6><p id=0>Unruled Ruled 100% 90% 80% 70% 60% F-Measure 50% 40% 30% 20% 10% 0% Yildiz FineReader Nitro Nurminen Silva Acrobat XI Pro OmniPage</p><p id=1>Fig. 1. Comparison of results with ruled versus unruled tables for the complete process sub-competition</p><p id=2>returned large false positive regions, whose table structure consisted of only one cell. In many cases, this huge cell only neighboured one or two other cells, and therefore did not raise the overall false positive count significantly.</p><p id=3>A further issue with our structure recognition metric is in the comparison of adjacency relations by their textual content. Although our normalization routine stripped or replaced most special characters, there were still some remaining encoding issues when evaluating certain approaches. This is a double- edged sword, as removing all non-alphanumeric characters would make it no longer possible to distinguish between cells that do not contain at least one letter or number, of which there were many in our dataset. In the future, we will therefore consider requiring further information about the cell, such as a bounding box, to enable its unique identification.</p><h1>ACKNOWLEDGMENTS</h1><p id=4>This work has been supported by the EU FP7 Marie Curie Zukunftskolleg Incoming Fellowship Programme, University of Konstanz (grant no. 291784), the ERC grant agreement DIADEM (no. 246858) and by the Oxford Martin School (grant no. LC0910-019).</p><h1>REFERENCES</h1><p id=4></p><ol type=1 start= 1><li>  M. C. GÃ¶bel, T. Hassan, E. Oro, and G. Orsi, "A methodology for evaluating algorithms for table understanding in PDF documents," in ACM Symposium on Document Engineering, 2012, pp. 45-48.</li><li>  E. Oro and M. Ruffolo, "PDF-TREX: An approach for recognizing and extracting tables from PDF documents," in Proc. of ICDAR, 2009, pp. 906-910.</li><li>  B. Krupl and M. Herzog, "Visually guided bottom-up table detection and segmentation in web documents," in WWW, 2006, pp. 933-934.</li><li>  A. C. e Silva, "Metrics for evaluating performance in document analysis: application to tables," IJDAR, vol. 14, no. 1, pp. 101-109, 2011.</li><li>  J. Fang, L. Gao, K. Bai, R. Qiu, X. Tao, and Z. Tang, "A table detection method for multipage PDF documents via visual seperators and tabular structures," in ICDAR, 2011, pp. 779-783.</li><li>  Y. Liu, K. Bai, P. Mitra, and C. L. Giles, "TableSeer: automatic table metadata extraction and searching in digital libraries," in JCDL, 2007, pp. 91-100.</li><li>  B. Yildiz, K. Kaiser, and S. Miksch, "pdf2table: A method to extract table information from pdf files," in IICAI, 2005, pp. 1773-1785.</li><li>  A. C. e Silva, "Parts that add up to a whole: a framework for the analysis of tables," Ph.D. dissertation, The University of Edinburgh, 2010.</li><li>  H. Strobelt, D. Oelke, C. Rohrdantz, A. Stoffel, D. A. Keim, and O. Deussen, "Document cards: A top trumps visualization for docu- ments," IEEE Trans. Vis. Comput. Graph ., vol. 15, no. 6, pp. 1145-1152, 2009.</li><li>  A. Stoffel, D. Spretke, H. Kinnemann, and D. A. Keim, "Enhancing document structure analysis using visual analytics," in SAC, 2010, pp. 8-12</li></ol></span><body></html>