<html><head><style>
        table, th, td {
          border: 1px solid black;
          border-collapse: collapse;
        }
        </style></head><body><h6>Page 1</h6><span idx = 1><h6>Column 1</h6><p id=0>TABLE I: Number of word and variable images in the testing datasets</p><table><tr><td>Number of word images </td><td>Number </td><td>of variable images </td></tr><tr><td></td><td>Variable containing a single character </td><td>Variable containing a single character and an index </td></tr><tr><td>420 </td><td>308 </td><td>72 </td></tr></table></br></br><p id=1>TABLE II: Classification accuracy results (Bold value indicates the highest scores of the methods)</p><table><tr><td>Methods </td><td>Precision </td><td>Recall </td><td>F-score </td></tr><tr><td>Method using orientation of gradient [11] </td><td>86.38% </td><td>76.81% </td><td>81.31% </td></tr><tr><td>Method using DWT [12] </td><td>92.63% </td><td>83.45% </td><td>87.80% </td></tr><tr><td>Method using the fine-tuning of Alexnet Method using the fine-tuning of ResNet-50 </td><td>93.38% 94.13% </td><td>86.58% 88.25% </td><td>89.85% 91.09% </td></tr><tr><td>Method using Alexnet and SVM Method using ResNet-50 and SVM </td><td>98.13% 99.5% </td><td>96.11% 98.95% </td><td>97.11% 99.23% </td></tr></table></br></br><p id=1>Methods pair 21</p><ol type=A start= 1><li> </li><li>  Fig. 4: Examples of a word (a); a variable contains a single character (b) and a variable contains an index (c)</li></ol><p id=2>25 20 15 10 0 -56000 -10 -15 O jega 80 O 20 -25 15 - 10</p><p id=3>Fig. 5: Representation of feature of variable and word extracted by Resnet-50 B. Performance evaluation</p><p id=4>1) Baseline and performance measures: As a baseline, the existing methods in [11] and [12] are used for the classification of variable and word. Moreover, fine-tuning CNNs is used for evaluating the performance of the classification. Fine-tuning a network is the reuse of a tuned network for a new task of out-performance comes from the fact that the CNNs allow classification. The technique is adopted because the number of variable and word images is not enough to train the CNNs Fig. 5 illustrates the features of 340 images of each type from scratch. By using the technique, the variable and word images are classified by the Softmax classifier that is the last layer of the CNNs.</p><p id=5>In our work, the Precision (P), Recall (R) and F1 score are used for the performance evaluation. Precision is the proportion of the true positives against all the positive results; Recall is the proportion of the true positives against all the true results and F1 score is the harmonic mean of precision and recall.</p></span><span idx = 2><h6>Column 2</h6><p id=0>Ri (c) Textual word Variable 10 15 20</p><p id=1>2) Performance: The performance comparisons of the proposed method and existing ones are shown in the table II. Comparing to traditional methods, the uses of CNNs and SVM in our work show higher accuracy. The accuracy in the classification of variable and textual word much improves. The to extract features of images better than existing methods. of variable and word that are extracted by Resnet-50. The feature distribution is represented by using the dimensional reduction technique that is Principal Component Analysis (PCA) [19]. Actually, 1000 features of variable and word images are extracted by using Resnet-50. The PCA technique allows to represent the features in 2-D space efficiently. The feature representation illustrates the classification possibility of variable and textual word. The method using orientation of gradient in [11] heavily relies on the calculation of skew</p></span><body></html>