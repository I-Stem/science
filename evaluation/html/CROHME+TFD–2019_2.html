<html><head><style>
        table, th, td {
          border: 1px solid black;
          border-collapse: collapse;
        }
        </style></head><body><h6>Page 1</h6><span idx = 1><h6>Column 1</h6><p id=1>TABLE I: CROHME 2019 DATA SETS</p><table><tr><td>Tasks </td><td>Training </td><td>Validation </td><td>Test </td></tr><tr><td>Formulae (1, 2) </td><td>Train 2014 + Test 2013 + Test 2012 9993 expr </td><td>Test 2014 986 expr </td><td>Test 2019 1199 expr </td></tr><tr><td>Symbols (la, 2a) </td><td>Train 2014 + Test 2013 + Test 2012 180440 symbols + junks </td><td>Test 2014 18435 symbols + junks </td><td>Test 2016 15483 symbols + junks </td></tr><tr><td>Structure (1b, 2b) </td><td>Train 2014 + Test 2013 + Test 2012 9993 expr </td><td>Test 2014 986 expr </td><td>Test 2016 1147 expr </td></tr><tr><td>Formula Detection (3) </td><td>36 rendered PDFs (600dpi): 569 pages 26395 formula regions Character BBs and labels </td><td>n/a </td><td>10 rendered PDFs (600dpi): 236 pages 11885 formula regions Character BBs without labels </td></tr></table></br></br><p id=2>to render images. Participants then convert these handwritten the isolated symbol sub-task, isolated symbols are rendered at formula images to a Symbol Layout Tree. For evaluation, the same evaluation tools are used as for Task 1. Again, participants are ranked by the expression rate of their system. participants were welcome to resize the original images using</p><p id=3>. Task 2a (symbols): subtask where participants recog- pre-processing methods of their choice. nize isolated symbols, including 'junk' (invalid symbols). Ranked by symbol recognition rate. Task 2b (parsing from provided symbols): subtask where participants parse formulas from provided symbols (bounding boxes + labels). Ranked by expression rate.</p><p id=4>Task 3. Detection of Formulas in Document Pages. Given a document page along with the bounding boxes of characters on that page (as are available for born-digital PDF files), participating systems identify formulas using bounding boxes. Evaluation is performed using Intersection-over-Union (IoU, or equivalently the Jaccard similarity coefficient), and systems expression '2+3c.' In the Stroke Label Graph (LG), there are 5 are ranked based on their F-measure after matching output nodes (one per stroke), and edges represent segmentation and formula boxes to ground truth formula regions.</p><h1>III. DATASETS AND FORMULA ENCODINGS</h1><p id=5>In this Section we describe data used in the competition, how it was collected, and the encodings used. Table I summarizes the datasets used for the competition.</p><p id=6>Handwritten Formulas: Input Data. For Task 1, we use online data in the same InkML and Label Graph (LG) file formats from previous CROHMEs. Strokes are defined by lists of (x,y) coordinates, representing sampled points as a stroke is written. Groupings of strokes into symbols, symbol our symLG representation, we use an adjacency matrix. Labels labels, and formula structure are provided in both the InkML and LG formats. In InkML structure is represented using elements represent spatial relationships between parent and Presentation MathML (an XML-based representation), while in LG a simpler CSV-based representation is used. In both cases, formula structure is represented by a Symbol Layout Tree, as seen in Figure 1(b). Roughly speaking, this format and relationships in a symLG file and the input data (i.e ., represents the appearance of a formula by the placement of symbols on the different writing lines of the expression. Spatial relationships between symbols (e.g, 'R' for adjacent-at-right) level LG files at the symbol level to be used directly. We are indicated using edge labels.</p><p id=7>For Task 2, the offline formula data is provided as greyscale images. These were rendered automatically from the online data with 1000 x 1000 pixels with 5 pixels of padding. This format is used for the main task (Task 2) and Task 2b. For</p></span><span idx = 2><h6>Column 2</h6><p id=1>28 Ã— 28 pixels with the same amount of padding (5 pixels). The resolution of the inputs files is fixed for Task 2, but</p><p id=2>Symbol Layout Graph (symLG) Formula Representation. The stroke-based LG files used in previous CROHMEs allow all segmentation, classification, and structural errors to be identified unambiguously, even when segmentations disagree [1]. However, with the success of encoder-decoder- based systems that generate LATEX output, a new representation is needed - these systems do not output information about stroke segmentation or the location of symbols in the input, instead producing Symbol Layout Trees directly.</p><p id=3>Figure 1 shows two graph representations for the same spatial relationships between pairs of strokes (including 'no relationship'). For the Stroke Label Graph, node identifiers are for individual strokes. In the Symbol Label Graph (symLG),</p><p id=4>there are 4 nodes (one per symbol) and edges represent relationships between symbols (no segmentation information is provided). For symLG, node identifiers are constructed from the sequence of relation labels on the path from root to the symbol. For example, 'c' in Figure 1 has the identifier 'oRRSup' (origin/root, Right, Right, Superscript).</p><p id=5>To compute the similarity of two Symbol Layout Trees in on the diagonal define symbol labels, while off-diagonal child symbols. Using this representation, we can determine how formulas in an SLT representation differ in structure and symbol labels, but not the correspondence between symbols</p><p id=6>strokes/images). Still, the symLG representation allows existing metrics and tools designed for evaluation of stroke- note that symLG is closely related to the tree-based symbolic representation from earlier CROHME competitions [1], but permits more detailed error analysis.</p><p id=7>Formula Data Collection. We used the labeled handwritten formulae from previous CROHMEs that are publicly available</p></span><body></html>